{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hack_training_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "teadh-tAHCZV",
        "colab_type": "code",
        "outputId": "71afcd5f-b8d5-4dde-f417-53cd93d305d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from random import shuffle\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, AveragePooling2D, Input, Flatten, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.applications.xception import *\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from keras.models import Model, Sequential\n",
        "import pickle \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5CAL8x2HeGQ",
        "colab_type": "code",
        "outputId": "09d25dab-2f70-4798-f684-54d311499a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxwUVAvzHTZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes=4\n",
        "img_size=299\n",
        "height=299\n",
        "width=299\n",
        "batch_size=16\n",
        "epochs=15\n",
        "scoring_set= \"drive/My Drive/private_scoring\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYduDeLUHdn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset= \"drive/My Drive/train/\"\n",
        "dir=os.listdir(dataset)\n",
        "# test_dir= \"D:/CNN/Datasets/test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMTHZuoRHWa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subtract_pixel_mean= False\n",
        "data_augmentation= False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQGJA8ukH3qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_train_data():\n",
        "    total_train_images=0\n",
        "    training_data= []\n",
        "    label=0\n",
        "    for i in dir:       \n",
        "        class_dir= os.path.join(dataset, i) #return a list of string where string is the name of the image             \n",
        "        images_list= os.listdir(class_dir)  \n",
        "        print(\"class\\t\", i, len(images_list))  \n",
        "        for image in tqdm(images_list):\n",
        "            img_path= os.path.join(class_dir, image)            \n",
        "            img_arr= cv2.imread(img_path, 1) # 0 for grayscale image >> img_arr is array of pixels\n",
        "            new_img= cv2.resize(img_arr, (height, width))\n",
        "            training_data.append([np.array(new_img),np.array(label)])\n",
        "        print(label)\n",
        "        label=label+1        \n",
        "    shuffle(training_data)    \n",
        "    return training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdvqajbHIAsH",
        "colab_type": "code",
        "outputId": "33f4e816-6d79-4639-8d1b-08f8cedfefb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# None- 380\n",
        "# car- 394\n",
        "# bike- 339\n",
        "# person- 286\n",
        "\n",
        "training_data = create_train_data()\n",
        "training_data= np.array(training_data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  6%|▌         | 22/380 [00:00<00:01, 217.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "class\t none 380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 380/380 [00:43<00:00,  1.14s/it]\n",
            "  0%|          | 0/394 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "class\t cars 394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 394/394 [07:37<00:00,  1.18s/it]\n",
            "  0%|          | 0/339 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "class\t bike 339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 339/339 [06:34<00:00,  1.14s/it]\n",
            "  0%|          | 0/286 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "class\t person 286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 286/286 [05:44<00:00,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxTyV0THuvUA",
        "colab_type": "code",
        "outputId": "b3bf255b-b91f-4681-9607-f0d777155234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#split into train and validation after shuffling of data\n",
        "x_train= np.array([i[0] for i in training_data])\n",
        "y_train= np.array([i[1] for i in training_data])\n",
        "\n",
        "\n",
        "#split train data into train and val set\n",
        "# x_train, x_val, y_train, y_val= train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"shape after splitting train, val and test sets\\n\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "# print(x_val.shape)\n",
        "# print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape after splitting train, val and test sets\n",
            "\n",
            "(1399, 299, 299, 3)\n",
            "(1399,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxHEIl0Iu-D0",
        "colab_type": "code",
        "outputId": "f72cc1d7-d559-4567-c9ff-7545191583b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#one hot encoding\n",
        "y_train= to_categorical(y_train, num_classes) \n",
        "# y_val= to_categorical(y_val, num_classes) \n",
        "\n",
        "print(\"after hot encoding\", y_train.shape)\n",
        "    \n",
        "#reshape data\n",
        "x_train = x_train.reshape(x_train.shape[0], img_size, img_size, 3)\n",
        "\n",
        "# x_val = x_val.reshape(x_val.shape[0], img_size, img_size, 3)\n",
        "# x_test = x_test.reshape(x_test.shape[0], img_size, img_size, 3)\n",
        "\n",
        "print(\"shape after reshaping train, val and test sets\\n\")\n",
        "print(\"train\", x_train.shape)\n",
        "# print(\"val\", x_val.shape)\n",
        "# print(\"test\", x_test.shape)\n",
        "\n",
        "#If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_val -= x_train_mean\n",
        "    x_test -= x_train_mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after hot encoding (1399, 4)\n",
            "shape after reshaping train, val and test sets\n",
            "\n",
            "train (1399, 299, 299, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzmfBMprWYoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Early stopping will stop the model from training before the number of epochs is reached if the model stops improving. We will set our\n",
        "# early stopping monitor to 3. This means that after 3 epochs in a row in which the model doesn’t improve, training will stop. Sometimes, \n",
        "# the validation loss can stop improving then improve in the next epoch, but after 3 epochs in which the validation loss doesn’t improve, \n",
        "# it usually won’t improve again.\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "#set early stopping monitor so the model stops training when it won't improve anymore\n",
        "early_stopping_monitor = EarlyStopping(patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4NiNvltvElR",
        "colab_type": "code",
        "outputId": "ce190da5-d8ec-448c-95ee-5a57379ad4ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "base_model = Xception(weights='imagenet', input_shape=(img_size, img_size, 3), include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0709 02:45:35.374341 140663823062912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0709 02:45:35.417170 140663823062912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0709 02:45:35.424211 140663823062912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0709 02:45:35.458673 140663823062912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0709 02:45:35.459583 140663823062912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0709 02:45:38.049117 140663823062912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0709 02:45:38.427291 140663823062912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0709 02:45:50.966895 140663823062912 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ85KObceXXi",
        "colab_type": "code",
        "outputId": "db0c397b-028e-4f00-ccdb-52454d40df6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "model.compile(optimizer='Adadelta',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0709 02:45:51.036337 140663823062912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiS3PfEjDn5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rescale=1.0/255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.5,\n",
        "        zoom_range=(0.9, 1.1),\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        fill_mode='constant',\n",
        "        cval=0\n",
        ")\n",
        "\n",
        "\n",
        "# get batch iterator\n",
        "train_iterator = datagen.flow(x_train, y_train,batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlOMmIRKVLC1",
        "colab_type": "code",
        "outputId": "f92ab2f0-ba5e-4b34-ee46-e8ffa167643e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "H = model.fit_generator(train_iterator, \n",
        "                       \n",
        "                        shuffle=True,\n",
        "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        epochs=epochs, \n",
        "                        verbose=1, \n",
        "                        callbacks=[early_stopping_monitor])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "87/87 [==============================] - 58s 663ms/step - loss: 0.4053 - acc: 0.8793\n",
            "Epoch 2/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "87/87 [==============================] - 58s 663ms/step - loss: 0.3471 - acc: 0.9021\n",
            "Epoch 3/15\n",
            "87/87 [==============================] - 57s 660ms/step - loss: 0.2562 - acc: 0.9278\n",
            "Epoch 4/15\n",
            "87/87 [==============================] - 57s 658ms/step - loss: 0.1812 - acc: 0.9423\n",
            "Epoch 5/15\n",
            "87/87 [==============================] - 57s 659ms/step - loss: 0.1241 - acc: 0.9612\n",
            "Epoch 6/15\n",
            "87/87 [==============================] - 57s 659ms/step - loss: 0.1612 - acc: 0.9583\n",
            "Epoch 7/15\n",
            "87/87 [==============================] - 57s 659ms/step - loss: 0.1153 - acc: 0.9670\n",
            "Epoch 8/15\n",
            "87/87 [==============================] - 57s 660ms/step - loss: 0.1090 - acc: 0.9655\n",
            "Epoch 9/15\n",
            "87/87 [==============================] - 57s 660ms/step - loss: 0.1008 - acc: 0.9727\n",
            "Epoch 10/15\n",
            "87/87 [==============================] - 57s 659ms/step - loss: 0.0884 - acc: 0.9806\n",
            "Epoch 11/15\n",
            "87/87 [==============================] - 57s 659ms/step - loss: 0.0672 - acc: 0.9835\n",
            "Epoch 12/15\n",
            "87/87 [==============================] - 57s 657ms/step - loss: 0.0604 - acc: 0.9828\n",
            "Epoch 13/15\n",
            "87/87 [==============================] - 57s 659ms/step - loss: 0.0858 - acc: 0.9770\n",
            "Epoch 14/15\n",
            "87/87 [==============================] - 57s 658ms/step - loss: 0.0985 - acc: 0.9712\n",
            "Epoch 15/15\n",
            "87/87 [==============================] - 57s 659ms/step - loss: 0.0409 - acc: 0.9899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF67RMNbDnDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('drive/My Drive/hack_training.h5')\n",
        "# An H5 file is a data file saved in the Hierarchical Data Format (HDF). It contains multidimensional arrays of scientific data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nWTUBNiwqtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"drive/My Drive/hack_training.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEVnBuafwuPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKRfRKsZ0wF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKWTbb3jguvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}