{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_Plant_seedling_comp.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CKmJKBnwbhx",
        "colab_type": "code",
        "outputId": "e3dcda72-eea9-480a-9fb5-19c16f976b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from random import shuffle\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.applications.xception import *\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2-iC6qw1U46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with subtract pixel mean:92%\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHSvCKAoFlr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes=12\n",
        "img_size=229\n",
        "height=229\n",
        "width=229\n",
        "batch_size=16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOmRllAKFqjb",
        "colab_type": "code",
        "outputId": "12e37f47-a775-4f0b-9341-5b2224e36531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-uO-M_ew3Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset= \"drive/My Drive/kaggle_competition/train/\"\n",
        "dir=os.listdir(dataset)\n",
        "# test_dir= \"D:/CNN/Datasets/test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTg6XekoFlAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_NnWzoM0O8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(os.getcwd())\n",
        "# os.chdir('content/drive/kaggle_competition/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXswJ4NhwfAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZmTda1rwhbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subtract_pixel_mean= False\n",
        "data_augmentation= False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qCEfWk5wjH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_train_data():\n",
        "    total_train_images=0\n",
        "    training_data= []\n",
        "    label=0\n",
        "    for i in dir:       \n",
        "        class_dir= os.path.join(dataset, i) #return a list of string where string is the name of the image             \n",
        "        images_list= os.listdir(class_dir)  \n",
        "        print(\"class\\t\", i, len(images_list))  \n",
        "        for image in tqdm(images_list):\n",
        "            img_path= os.path.join(class_dir, image)            \n",
        "            img_arr= cv2.imread(img_path, 1) # 0 for grayscale image >> img_arr is array of pixels\n",
        "            new_img= cv2.resize(img_arr, (height, width))\n",
        "            training_data.append([np.array(new_img),np.array(label)])\n",
        "        print(label)\n",
        "        label=label+1        \n",
        "    shuffle(training_data)    \n",
        "    return training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BswA7A2-DDvl",
        "colab_type": "code",
        "outputId": "e063a48e-bcce-45e8-f6fc-0c7b968c2835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        }
      },
      "source": [
        "training_data = create_train_data()\n",
        "training_data= np.array(training_data)\n",
        "print(training_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 9/654 [00:00<00:07, 85.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "class\t Loose Silky-bent 654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 654/654 [00:07<00:00, 82.09it/s]\n",
            "  5%|▍         | 25/516 [00:00<00:02, 241.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "class\t Scentless Mayweed 516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 516/516 [00:02<00:00, 185.01it/s]\n",
            "  3%|▎         | 10/385 [00:00<00:03, 98.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "class\t Sugar beet 385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [00:06<00:00, 63.31it/s]\n",
            "  5%|▌         | 12/221 [00:00<00:01, 118.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "class\t Common wheat 221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 221/221 [00:02<00:00, 93.27it/s] \n",
            "  1%|          | 2/221 [00:00<00:12, 18.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "class\t Maize 221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 221/221 [00:03<00:00, 72.28it/s]\n",
            "  3%|▎         | 17/496 [00:00<00:03, 154.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "class\t Small-flowered Cranesbill 496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 496/496 [00:03<00:00, 134.48it/s]\n",
            "  5%|▍         | 13/287 [00:00<00:02, 127.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "class\t Cleavers 287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 287/287 [00:01<00:00, 157.56it/s]\n",
            "  3%|▎         | 21/611 [00:00<00:02, 205.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "class\t Common Chickweed 611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [00:03<00:00, 192.41it/s]\n",
            "  9%|▊         | 20/231 [00:00<00:01, 195.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "class\t Shepherds Purse 231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231/231 [00:01<00:00, 147.50it/s]\n",
            "  4%|▍         | 21/475 [00:00<00:02, 205.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "class\t Fat Hen 475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 475/475 [00:03<00:00, 151.37it/s]\n",
            "  1%|          | 3/263 [00:00<00:13, 18.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "class\t Black-grass 263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 263/263 [00:05<00:00, 45.92it/s] \n",
            "  1%|          | 4/390 [00:00<00:12, 31.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "class\t Charlock 390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 390/390 [00:04<00:00, 95.62it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11\n",
            "(4750, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iiHFi0PNVc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_test_data():\n",
        "#     testing_data=[]\n",
        "    \n",
        "#     images_list=os.listdir(test_dir) \n",
        "#     total_test_images= len(images_list) \n",
        "   \n",
        "#     for image in tqdm(images_list):  \n",
        "#         path= os.path.join(test_dir, image) \n",
        "#         new_image=cv2.resize(cv2.imread(path, 1), (height, width)) \n",
        "#         testing_data.append(np.array(new_image))\n",
        "    \n",
        "#     np.save('D:/CNN/Datasets/Plant_testing.npy', testing_data)\n",
        "#     return testing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFdDgFTqFO_l",
        "colab_type": "code",
        "outputId": "cdccaf8b-5dc3-462f-dce0-dbc901900d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "x_train= np.array([i[0] for i in training_data])\n",
        "y_train= [i[1] for i in training_data]\n",
        "\n",
        "#split train data into train and val set\n",
        "x_train, x_val, y_train, y_val= train_test_split(x_train, y_train, test_size=0.2)\n",
        "\n",
        "print(\"shape after splitting train, val and test sets\\n\")\n",
        "print(x_train.shape)\n",
        "print(len(y_train))\n",
        "print(x_val.shape)\n",
        "print(len(y_val))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape after splitting train, val and test sets\n",
            "\n",
            "(3800, 229, 229, 3)\n",
            "3800\n",
            "(950, 229, 229, 3)\n",
            "950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJpiPvRhNUms",
        "colab_type": "code",
        "outputId": "417e9b19-7b22-421e-befb-907ec304d34a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "#preprocessing\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_val = x_val.astype('float32') / 255\n",
        "# x_test = x_test.astype('float32') / 255\n",
        "    \n",
        "#one hot encoding\n",
        "y_train= to_categorical(y_train, num_classes) \n",
        "y_val= to_categorical(y_val, num_classes) \n",
        "\n",
        "print(\"after hot encoding\", y_train.shape, y_val.shape)\n",
        "    \n",
        "#reshape data\n",
        "x_train = x_train.reshape(x_train.shape[0], height, width, 3)\n",
        "x_val = x_val.reshape(x_val.shape[0], height, width, 3)\n",
        "# x_test = x_test.reshape(x_test.shape[0], height, width, 3)\n",
        "\n",
        "print(\"shape after reshaping train, val and test sets\\n\")\n",
        "print(\"train\", x_train.shape)\n",
        "print(\"val\", x_val.shape)\n",
        "# print(\"test\", x_test.shape)\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_val -= x_train_mean\n",
        "#     x_test -= x_train_mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after hot encoding (3800, 12) (950, 12)\n",
            "shape after reshaping train, val and test sets\n",
            "\n",
            "train (3800, 229, 229, 3)\n",
            "val (950, 229, 229, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnIKQeWVDG77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_mask_for_plant(image):\n",
        "#     image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "#     sensitivity = 35\n",
        "#     lower_hsv = np.array([60 - sensitivity, 100, 50])\n",
        "#     upper_hsv = np.array([60 + sensitivity, 255, 255])\n",
        "\n",
        "#     mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n",
        "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
        "#     mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    \n",
        "#     return mask\n",
        "\n",
        "# def segment_plant(image):\n",
        "#     mask = create_mask_for_plant(image)\n",
        "#     output = cv2.bitwise_and(image, image, mask = mask)\n",
        "#     return output\n",
        "  \n",
        "# def sharpen_image(image):\n",
        "#     image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "#     image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
        "#     return image_sharp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgYX8MKgFOIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_segmented = segment_plant(image_bgr)\n",
        "# image_sharpen = sharpen_image(image_segmented)\n",
        "# cv2.imwrite(os.path.join('seg_test', file), image_sharpen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXpzrM4XHNFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "#                              rotation_range=180,\n",
        "#                              width_shift_range=0.3,\n",
        "#                              height_shift_range=0.3,\n",
        "#                              zoom_range=0.3,\n",
        "#                              horizontal_flip=True,\n",
        "#                              vertical_flip=True)\n",
        "\n",
        "# datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gy4hseUHSIv",
        "colab_type": "code",
        "outputId": "1347e603-bd9c-4a35-c9da-b96f54785ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "base_model = Xception(weights='imagenet', input_shape=(img_size, img_size, 3), include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(12, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0707 09:53:57.915254 140587020388224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0707 09:53:57.938483 140587020388224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0707 09:53:57.943226 140587020388224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0707 09:53:57.966517 140587020388224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0707 09:53:57.968707 140587020388224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0707 09:53:58.568691 140587020388224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0707 09:53:58.960316 140587020388224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0707 09:54:04.474060 140587020388224 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKlzjwB6HQxB",
        "colab_type": "code",
        "outputId": "0a953501-d54a-4ac5-d6e5-01d90d112a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "model.compile(optimizer='Adadelta',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0707 09:54:04.540722 140587020388224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KcdwxoRHSvg",
        "colab_type": "code",
        "outputId": "ce9b8963-b412-4ea1-d29e-ca7f1c275a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "\n",
        "model.fit(x_train, y_train, batch_size= batch_size,\n",
        "            \n",
        "                    epochs=10, \n",
        "                    validation_data=(x_val, y_val), \n",
        "                    verbose=1)\n",
        "\n",
        "model.save_weights('Xception.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0707 09:54:04.691733 140587020388224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3800 samples, validate on 950 samples\n",
            "Epoch 1/10\n",
            "3800/3800 [==============================] - 102s 27ms/step - loss: 1.1000 - acc: 0.6529 - val_loss: 1.4038 - val_acc: 0.7168\n",
            "Epoch 2/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.4149 - acc: 0.8774 - val_loss: 0.5005 - val_acc: 0.8611\n",
            "Epoch 3/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.2841 - acc: 0.9163 - val_loss: 0.4012 - val_acc: 0.9126\n",
            "Epoch 4/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.1907 - acc: 0.9413 - val_loss: 0.4316 - val_acc: 0.8989\n",
            "Epoch 5/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.1260 - acc: 0.9603 - val_loss: 0.3018 - val_acc: 0.9326\n",
            "Epoch 6/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.1341 - acc: 0.9624 - val_loss: 0.4137 - val_acc: 0.9084\n",
            "Epoch 7/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.0923 - acc: 0.9745 - val_loss: 0.2140 - val_acc: 0.9442\n",
            "Epoch 8/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.1085 - acc: 0.9729 - val_loss: 0.2146 - val_acc: 0.9516\n",
            "Epoch 9/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.0678 - acc: 0.9813 - val_loss: 0.2407 - val_acc: 0.9432\n",
            "Epoch 10/10\n",
            "3800/3800 [==============================] - 91s 24ms/step - loss: 0.0642 - acc: 0.9818 - val_loss: 0.3014 - val_acc: 0.9305\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}